# ğŸŒ¾ TPT BIHAR 2025 â€“ Projet Final

## ğŸ“Œ Objectifs

Ce projet regroupe trois volets dâ€™apprentissage automatique :

1. **Classification dâ€™images** (CNNs)
2. **Analyse de sentiments** (Textes avec LSTM/NLP)
3. **PrÃ©vision de sÃ©ries temporelles** (ARIMA, ML, MLOps)

Le projet **sÃ©ries temporelles** intÃ¨gre une chaÃ®ne MLOps complÃ¨te avec base de donnÃ©es, API FastAPI, scripts de monitoring et pipeline CI/CD.

---

## ğŸ“ Structure du projet

```
notebooks/
â”‚   â”œâ”€â”€ image_classification.ipynb         # CNNs sur des images
â”‚   â”œâ”€â”€ text_classification.ipynb          # LSTM / analyse de sentiments
â”‚   â””â”€â”€ timeseries_forecasting.ipynb       # PrÃ©vision de tempÃ©rature

data/
â”‚   â”œâ”€â”€ acquisition.py                     # Script de rÃ©cupÃ©ration des donnÃ©es rÃ©centes
â”‚   â”œâ”€â”€ forecast_results.db                # Base SQLite stockant les prÃ©dictions et targets
â”‚   â””â”€â”€ configs/                           # Configs YAML pour l'acquisition ET l'entraÃ®nement des modÃ¨les
â”‚       â”œâ”€â”€ acquisition_config.yaml         # Configuration de l'acquisition des donnÃ©es mÃ©tÃ©o
â”‚       â”œâ”€â”€ arima_config.yaml              # Configuration du modÃ¨le ARIMA
â”‚       â”œâ”€â”€ sarima_config.yaml             # Configuration du modÃ¨le SARIMA
â”‚       â”œâ”€â”€ sarimax_config.yaml            # Configuration du modÃ¨le SARIMAX
â”‚       â””â”€â”€ ml_config.yaml                 # Configuration pour les modÃ¨les de machine learning

model/
â”‚   â”œâ”€â”€ generate_prediction.py             # Script de gÃ©nÃ©ration de prÃ©dictions Ã  une date donnÃ©e
â”‚   â”œâ”€â”€ train_pipeline.py                  # EntraÃ®nement des modÃ¨les (ARIMA, ML, etc.) via fichier de config
â”‚   â””â”€â”€ registry/                          # ModÃ¨les entraÃ®nÃ©s enregistrÃ©s (pickle, joblib, etc.)

monitoring/
â”‚   â”œâ”€â”€ compare_predictions.py             # GÃ©nÃ©ration de graphiques comparant prÃ©dictions et observations
â”‚   â””â”€â”€ output/                            # Graphiques gÃ©nÃ©rÃ©s automatiquement

api/
â”‚   â”œâ”€â”€ main.py                            # API FastAPI
â”‚   â””â”€â”€ logs/                              # Journaux de l'API (app.log)

.github/
    â””â”€â”€ workflows/ci.yml                   # Pipeline CI/CD GitHub Actions
```

---

## âš™ï¸ Installation

```bash
# Cloner le repo
git clone <repo-url>
cd tp-bihar-2025

# CrÃ©er un environnement virtuel
python -m venv venv && source venv/bin/activate

# Installer les dÃ©pendances
pip install -r requirements.txt
```

---

## ğŸš€ Lancer l'API

```bash
uvicorn api.main:app --reload
```

Disponible sur `http://localhost:8000`

---

## ğŸ¥ª Tester lâ€™API

**RÃ©cupÃ©rer les prÃ©dictions Ã  une date donnÃ©e** :

```bash
curl -X GET "http://localhost:8000/predict?date=2024-01-06" | jq

curl -X GET "http://localhost:8000/predict?date=2024-09-06" | jq
```

**Obtenir les prÃ©dictions combinÃ©es avec targets** :

```bash
curl -X POST "http://localhost:8000/combined" \
     -H "Content-Type: application/json" \
     -d '{"start_date": "2024-01-01", "end_date": "2024-01-07"}' | jq
```

**Version logicielle** :

```bash
curl -X GET "http://localhost:8000/version" | jq
```

---

## ğŸ“Š GÃ©nÃ©ration de prÃ©dictions (hors API)

```bash
# Exemple : prÃ©dictions pour le 2024-01-06
python model/predict.py 2024-01-06
```

Ce script lit directement la base `data/forecast_results.db` et exporte un CSV des rÃ©sultats.

---

## ğŸ“‰ Monitoring (visualisation)

```bash
python monitoring/compare_predictions.py --date 2023-12-06
```

Une image de comparaison est gÃ©nÃ©rÃ©e dans `monitoring/output/`.

---

## ğŸ  Acquisition des donnÃ©es

Configurer le fichier `configs/acquisition_config.yaml`, puis exÃ©cuter :

```bash
python data/acquisition.py
```

Cela stocke les nouvelles donnÃ©es dans la base SQLite.

##### ğŸ“¥ TÃ©lÃ©chargement des donnÃ©es dâ€™images

Les donnÃ©es de classification dâ€™images ne peuvent pas Ãªtre versionnÃ©es avec le dÃ©pÃ´t Git.

Veuillez suivre les Ã©tapes suivantes pour prÃ©parer les donnÃ©es :

1. Rendez-vous sur Kaggle : [https://www.kaggle.com/datasets/rodrigonuneswessner/labeledcorndataset](https://www.kaggle.com/datasets/rodrigonuneswessner/labeledcorndataset)
2. Cliquez sur **Download** (vous devez avoir un compte Kaggle)
3. DÃ©compressez lâ€™archive tÃ©lÃ©chargÃ©e
4. Placez manuellement le dossier `ImagensTCCRotuladas/` dans le dossier `./data/`

La structure finale attendue est :

```
data/
â””â”€â”€ ImagensTCCRotuladas/
    â”œâ”€â”€ Train/
    â”œâ”€â”€ Validation/
    â””â”€â”€ Test/
```

Ces dossiers contiennent dÃ©jÃ  les images triÃ©es par classes (`Chao`, `Ervas`, `Milho`, `Milho_ervas`).

---

## ğŸ§± EntraÃ®nement des modÃ¨les

```bash
python model/train_pipeline.py --config configs/arima_config.yaml
```

Les fichiers YAML dans `configs/` dÃ©finissent les hyperparamÃ¨tres pour chaque type de modÃ¨le :

-  `arima_config.yaml`
-  `sarima_config.yaml`
-  `sarimax_config.yaml`
-  `ml_config.yaml`

Les modÃ¨les sont sauvegardÃ©s automatiquement dans `model/registry/`.

---

## ğŸ“¦ Dockerisation

```bash
docker build -t forecast-api .
docker run -p 8000:8000 forecast-api
```

---

## ğŸ” CI/CD GitHub Actions

La pipeline CI/CD effectue :

-  âœ… Build de l'image Docker
-  ğŸš€ Push sur GitHub Container Registry (GHCR)
-  ğŸ¨® Lancement des tests `pytest`
-  ğŸ”” Notifications sur les erreurs

Elle est dÃ©clenchÃ©e automatiquement Ã  chaque **push** dans le dÃ©pÃ´t.

---

## ğŸ¾ Journaux d'exÃ©cution (Logging)

Lâ€™API Ã©crit ses journaux dans `api/logs/app.log`. Les Ã©vÃ©nements enregistrÃ©s incluent :

-  âœ… RequÃªtes entrantes (`/predict`, `/combined`, `/version`)
-  ğŸ§ Nombre de prÃ©dictions chargÃ©es
-  âŒ Erreurs de base de donnÃ©es (fichiers absents ou vides)
-  ğŸ’¡ Commit ID de la version en cours

---

## ğŸ’² DÃ©pendances clÃ©s

```text
fastapi
uvicorn
pandas
scikit-learn
statsmodels
sqlalchemy
matplotlib
jupyter
pytest
joblib
httpx
```

---
