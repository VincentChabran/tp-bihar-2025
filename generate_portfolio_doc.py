from docx import Document
from docx.shared import Inches, Pt, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.enum.style import WD_STYLE_TYPE
from datetime import datetime

def create_portfolio_document():
    # CrÃ©er un nouveau document
    doc = Document()

    # DÃ©finir les styles personnalisÃ©s
    styles = doc.styles

    # Titre principal
    title = doc.add_heading('Projet TP BIHAR 2025', 0)
    title.alignment = WD_ALIGN_PARAGRAPH.CENTER

    # Sous-titre
    subtitle = doc.add_paragraph()
    subtitle.add_run('Portfolio - Double Master BIHAR & IngÃ©nierie Logicielle\n').bold = True
    subtitle.add_run('Vincent CHABRAN').italic = True
    subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
    doc.add_paragraph()

    # Section Vue d'ensemble
    doc.add_heading('ğŸ¯ Vue d\'ensemble', 1)
    doc.add_paragraph(
        'Ce projet constitue un projet complet de Machine Learning et MLOps dÃ©veloppÃ© dans le cadre '
        'du double master BIHAR et IngÃ©nierie Logicielle. Il dÃ©montre la maÃ®trise de trois domaines '
        'fondamentaux du ML : la vision par ordinateur, le traitement du langage naturel et l\'analyse '
        'de sÃ©ries temporelles, avec une implÃ©mentation complÃ¨te d\'une chaÃ®ne MLOps.'
    )
    doc.add_paragraph()

    # Section CompÃ©tences techniques
    doc.add_heading('ğŸ› ï¸ CompÃ©tences techniques dÃ©montrÃ©es', 1)

    # 1. Deep Learning & Computer Vision
    doc.add_heading('1. Deep Learning & Computer Vision', 2)
    cv_items = [
        'Architectures CNN : ImplÃ©mentation d\'un CNN baseline from scratch et utilisation de transfer learning avec VGG16',
        'PrÃ©traitement d\'images : Augmentation de donnÃ©es, normalisation, transforms PyTorch',
        'Classification multi-classes : Classification d\'images agricoles (maÃ¯s, herbes, sol) avec gestion de 3 et 4 classes',
        'Ã‰valuation : Matrices de confusion, courbes d\'apprentissage, analyse des mÃ©triques (accuracy jusqu\'Ã  86% avec VGG16)'
    ]
    for item in cv_items:
        doc.add_paragraph(item, style='List Bullet')

    # 2. Natural Language Processing
    doc.add_heading('2. Natural Language Processing', 2)
    nlp_items = [
        'Vectorisation de texte : TF-IDF, Word2Vec (modÃ¨les prÃ©-entraÃ®nÃ©s franÃ§ais)',
        'ModÃ¨les classiques : RÃ©gression logistique, SVM linÃ©aire (92% d\'accuracy)',
        'Deep Learning NLP : Architecture LSTM pour l\'analyse de sentiments',
        'PrÃ©traitement NLP : Nettoyage de texte, suppression des stopwords, tokenization',
        'Dataset : Travail sur le dataset Allocine (200k critiques de films en franÃ§ais)'
    ]
    for item in nlp_items:
        doc.add_paragraph(item, style='List Bullet')

    # 3. SÃ©ries temporelles
    doc.add_heading('3. SÃ©ries temporelles & PrÃ©vision', 2)
    ts_items = [
        'ModÃ¨les statistiques : ARIMA, SARIMA, SARIMAX avec recherche automatique des hyperparamÃ¨tres',
        'Machine Learning : Random Forest (RÂ² = 0.97), RÃ©gression linÃ©aire',
        'Feature engineering : CrÃ©ation de features temporelles (lags, moyennes mobiles, variables calendaires)',
        'Analyse statistique : Tests de stationnaritÃ© (ADF, KPSS), ACF/PACF, dÃ©composition STL',
        'DonnÃ©es mÃ©tÃ©o : IntÃ©gration API Open-Meteo, gestion des variables exogÃ¨nes'
    ]
    for item in ts_items:
        doc.add_paragraph(item, style='List Bullet')

    # 4. MLOps & Infrastructure
    doc.add_heading('4. MLOps & Infrastructure', 2)
    mlops_items = [
        'API REST : FastAPI avec endpoints documentÃ©s (Swagger)',
        'Base de donnÃ©es : SQLite avec ORM SQLAlchemy pour stockage des modÃ¨les et prÃ©dictions',
        'Monitoring : Scripts de comparaison prÃ©dictions/observations, gÃ©nÃ©ration de graphiques',
        'CI/CD : Pipeline GitHub Actions pour tests automatisÃ©s et dÃ©ploiement',
        'Versioning : Gestion des versions de modÃ¨les dans la DB',
        'Logging : SystÃ¨me de logs structurÃ©s pour l\'API'
    ]
    for item in mlops_items:
        doc.add_paragraph(item, style='List Bullet')

    # 5. Engineering Best Practices
    doc.add_heading('5. Engineering Best Practices', 2)
    eng_items = [
        'Architecture modulaire : SÃ©paration claire src/, notebooks/, data/, api/, monitoring/',
        'Tests unitaires : pytest pour validation de l\'API',
        'Configuration : Fichiers YAML pour paramÃ¨tres des modÃ¨les',
        'Documentation : README dÃ©taillÃ©, notebooks commentÃ©s, docstrings',
        'Containerisation : Support Docker pour dÃ©ploiement'
    ]
    for item in eng_items:
        doc.add_paragraph(item, style='List Bullet')

    doc.add_page_break()

    # Section RÃ©sultats
    doc.add_heading('ğŸ“ˆ RÃ©sultats notables', 1)

    # CrÃ©er un tableau des rÃ©sultats
    table = doc.add_table(rows=5, cols=3)
    table.style = 'Light List Accent 1'

    # En-tÃªtes du tableau
    headers = ['Domaine', 'ModÃ¨le', 'Performance']
    for i, header in enumerate(headers):
        cell = table.rows[0].cells[i]
        cell.text = header
        cell.paragraphs[0].runs[0].bold = True

    # DonnÃ©es du tableau
    data = [
        ['Vision', 'VGG16 (3 classes)', '86% accuracy'],
        ['NLP', 'TF-IDF + LogReg', '92% accuracy'],
        ['SÃ©ries temporelles', 'Random Forest', 'RÂ² = 0.97, RMSE = 0.91'],
        ['API', 'FastAPI', '3 endpoints REST fonctionnels']
    ]

    for row_idx, row_data in enumerate(data, start=1):
        for col_idx, cell_data in enumerate(row_data):
            table.rows[row_idx].cells[col_idx].text = cell_data

    doc.add_paragraph()

    # Points d'innovation
    doc.add_heading('ğŸ”¬ Points d\'innovation', 1)
    innovations = [
        'Pipeline MLOps complet : De l\'acquisition des donnÃ©es au dÃ©ploiement API',
        'Comparaison multi-modÃ¨les : Benchmark systÃ©matique (5 modÃ¨les pour les sÃ©ries temporelles)',
        'Gestion de la stationnaritÃ© : Transformation automatique et tests statistiques',
        'Feature engineering avancÃ© : Variables exogÃ¨nes mÃ©tÃ©o + features temporelles',
        'Architecture Ã©volutive : Base de donnÃ©es pour tracking des expÃ©riences'
    ]

    for i, innovation in enumerate(innovations, start=1):
        doc.add_paragraph(f'{i}. {innovation}')

    # Stack technologique
    doc.add_heading('ğŸ“š Stack technologique', 1)
    stack_items = {
        'Python': 'pandas, numpy, scikit-learn, statsmodels',
        'Deep Learning': 'PyTorch, TensorFlow/Keras',
        'MLOps': 'FastAPI, SQLAlchemy, Docker, GitHub Actions',
        'Visualisation': 'matplotlib, seaborn',
        'NLP': 'NLTK, gensim, transformers',
        'Tests': 'pytest, httpx'
    }

    for category, tools in stack_items.items():
        p = doc.add_paragraph()
        p.add_run(f'{category}: ').bold = True
        p.add_run(tools)

    doc.add_paragraph()

    # CompÃ©tences validÃ©es
    doc.add_heading('ğŸ“ CompÃ©tences validÃ©es pour le master', 1)
    skills = [
        'Machine Learning avancÃ© : MaÃ®trise des algorithmes classiques et deep learning',
        'MLOps : DÃ©ploiement et monitoring de modÃ¨les en production',
        'Analyse de donnÃ©es : EDA, feature engineering, validation croisÃ©e',
        'DÃ©veloppement logiciel : Clean code, tests, CI/CD',
        'Gestion de projet : Documentation, versioning Git, architecture modulaire'
    ]

    for skill in skills:
        p = doc.add_paragraph()
        p.add_run('âœ… ').bold = True
        parts = skill.split(' : ')
        p.add_run(parts[0] + ' : ').bold = True
        if len(parts) > 1:
            p.add_run(parts[1])

    doc.add_page_break()

    # Architecture du projet
    doc.add_heading('ğŸ“ Architecture du projet', 1)
    doc.add_paragraph('Structure complÃ¨te du repository :')

    architecture = """
notebooks/
    â”œâ”€â”€ image_classification.ipynb      # CNNs sur des images
    â”œâ”€â”€ text_classification.ipynb       # LSTM / analyse de sentiments
    â””â”€â”€ timeseries_forecasting.ipynb    # PrÃ©vision de tempÃ©rature

src/
    â”œâ”€â”€ image_classification/           # Modules pour la vision
    â”œâ”€â”€ text_classification/            # Modules pour le NLP
    â”œâ”€â”€ timeseries_forecasting/         # Modules pour les sÃ©ries temporelles
    â””â”€â”€ ForecastDatabase.py             # Interface base de donnÃ©es

data/
    â”œâ”€â”€ forecast_results.db             # Base SQLite
    â””â”€â”€ configs/                        # Configurations YAML des modÃ¨les

api/
    â”œâ”€â”€ main.py                         # API FastAPI
    â””â”€â”€ logs/                           # Journaux de l'API

monitoring/
    â”œâ”€â”€ compare_predictions.py          # Comparaison prÃ©dictions/observations
    â””â”€â”€ output/                         # Graphiques gÃ©nÃ©rÃ©s

tests/
    â”œâ”€â”€ test_predict.py                 # Tests unitaires
    â””â”€â”€ test_combined.py                # Tests d'intÃ©gration
    """

    doc.add_paragraph(architecture)

    # Lien GitHub
    doc.add_heading('ğŸ”— Liens et ressources', 1)
    p = doc.add_paragraph()
    p.add_run('Repository GitHub : ').bold = True
    p.add_run('https://github.com/vincentchabran/tp-bihar-2025')

    doc.add_paragraph()
    p = doc.add_paragraph()
    p.add_run('Date de gÃ©nÃ©ration : ').italic = True
    p.add_run(datetime.now().strftime('%d/%m/%Y'))

    # Sauvegarder le document
    filename = 'Portfolio_TP_BIHAR_2025.docx'
    doc.save(filename)
    print(f"âœ… Document crÃ©Ã© avec succÃ¨s : {filename}")
    return filename

if __name__ == "__main__":
    create_portfolio_document()